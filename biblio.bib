
@online{5starOpenData,
  title = {5-Star {{Open Data}}},
  url = {http://5stardata.info/en/},
  urldate = {2021-04-12},
  abstract = {Information around Tim Berners-Lee's 5-star Open Data Plan},
  file = {/home/alex/Zotero/storage/LMRBJAF6/en.html},
  langid = {english}
}

@online{addleseeComparingLinkedData2019,
  title = {Comparing {{Linked Data Triplestores}}},
  author = {Addlesee, Angus},
  date = {2019-01-22T23:57:00},
  url = {https://medium.com/wallscope/comparing-linked-data-triplestores-ebfac8c3ad4f},
  urldate = {2021-04-12},
  abstract = {Virtuoso, GraphDB, Blazegraph, Stardog, AnzoGraph and more…},
  file = {/home/alex/Zotero/storage/DRRR2V7K/comparing-linked-data-triplestores-ebfac8c3ad4f.html},
  langid = {english},
  organization = {{Medium}}
}

@inproceedings{antoniazziRDFGraphVisualization2018,
  title = {{{RDF Graph Visualization Tools}}: A {{Survey}}},
  shorttitle = {{{RDF Graph Visualization Tools}}},
  booktitle = {2018 23rd {{Conference}} of {{Open Innovations Association}} ({{FRUCT}})},
  author = {Antoniazzi, Francesco and Viola, Fabio},
  date = {2018-11},
  pages = {25--36},
  publisher = {{IEEE}},
  location = {{Bologna}},
  doi = {10.23919/FRUCT.2018.8588069},
  url = {https://ieeexplore.ieee.org/document/8588069/},
  urldate = {2021-04-12},
  abstract = {Semantic Web technologies are increasingly being used for the development of Future Internet applications, mainly due to the impressive growth of the Internet of Things research area. This spread pushes for effective and efficient ways to visualize the content of RDF ontologies and knowledge bases. Several strategies can be adopted to visualize semantic data and one of this consists in exploiting the graph representation intrinsic in the RDF model. In this paper, we propose a survey of the main tools for the graphical visualization of triples (being them terminological or assertional statements) exploiting a graph representation.},
  eventtitle = {2018 23rd {{Conference}} of {{Open Innovations Association}} ({{FRUCT}})},
  file = {/home/alex/Zotero/storage/3A3BGJQZ/Antoniazzi and Viola - 2018 - RDF Graph Visualization Tools a Survey.pdf},
  isbn = {978-952-68653-6-2},
  langid = {english}
}

@incollection{atemezingBenchmarkingCommercialRDF2018,
  title = {Benchmarking {{Commercial RDF Stores}} with {{Publications Office Dataset}}},
  booktitle = {The {{Semantic Web}}: {{ESWC}} 2018 {{Satellite Events}}},
  author = {Atemezing, Ghislain Auguste and Amardeilh, Florence},
  editor = {Gangemi, Aldo and Gentile, Anna Lisa and Nuzzolese, Andrea Giovanni and Rudolph, Sebastian and Maleshkova, Maria and Paulheim, Heiko and Pan, Jeff Z and Alam, Mehwish},
  date = {2018},
  volume = {11155},
  pages = {379--394},
  publisher = {{Springer International Publishing}},
  location = {{Cham}},
  doi = {10.1007/978-3-319-98192-5_54},
  url = {http://link.springer.com/10.1007/978-3-319-98192-5_54},
  urldate = {2021-04-12},
  abstract = {This paper presents a benchmark of RDF stores with realworld datasets and queries from the EU Publications Office (PO). The study compares the performance of four commercial triple stores: Stardog 4.3 EE, GraphDB 8.0.3 EE, Oracle 12.2c and Virtuoso 7.2.4.2 with respect to the following requirements: bulk loading, scalability, stability and query execution. The datasets and the selected queries (44) are used in the Linked Data publication workflow at PO. The first results of this study provides some insights into the quantitative performance assessment of RDF stores used in production environment in general, especially when dealing with large amount of triples. Virtuoso is faster in querying and loading scenarios while GraphDB shows better results regarding stability.},
  file = {/home/alex/Zotero/storage/K7GHPRQK/Atemezing and Amardeilh - 2018 - Benchmarking Commercial RDF Stores with Publicatio.pdf},
  isbn = {978-3-319-98191-8 978-3-319-98192-5},
  langid = {english},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{capadisliLinkedSDMXData2015,
  title = {Linked {{SDMX Data}}: {{Path}} to High Fidelity {{Statistical Linked Data}}},
  shorttitle = {Linked {{SDMX Data}}},
  author = {Capadisli, Sarven and Auer, Sören and Ngonga Ngomo, Axel-Cyrille},
  date = {2015},
  journaltitle = {Semantic Web},
  volume = {6},
  pages = {105--112},
  issn = {15700844},
  doi = {10.3233/SW-130123},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-130123},
  urldate = {2021-04-12},
  number = {2}
}

@article{cyganiakSemanticStatisticsBringing,
  title = {Semantic {{Statistics}}: {{Bringing Together SDMX}} and {{SCOVO}}},
  author = {Cyganiak, Richard and Field, Simon and Gregory, Arofan},
  pages = {5},
  abstract = {Whether it's population, income, unemployment or interest rates, statistical data is a fundamental source of information for analysis and visualisations. Many publishers of statistics use SDMX to represent statistics and make them available through web services. The linked data principles of identifying items with HTTP URIs and representing data using RDF provide some benefits (though also some costs) for statistical publishing. This paper describes how the SDMX information model can be used with linked data and RDF and describes some ongoing work to explore the impact of doing so.},
  file = {/home/alex/Zotero/storage/R6DENF5P/Cyganiak et al. - Semantic Statistics Bringing Together SDMX and SC.pdf},
  langid = {english}
}

@article{dadzieApproachesVisualisingLinked2011,
  title = {Approaches to Visualising {{Linked Data}}: {{A}} Survey},
  shorttitle = {Approaches to Visualising {{Linked Data}}},
  author = {Dadzie, Aba-Sah and Rowe, Matthew},
  date = {2011},
  journaltitle = {Semantic Web},
  volume = {2},
  pages = {89--124},
  issn = {15700844},
  doi = {10.3233/SW-2011-0037},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-2011-0037},
  urldate = {2021-04-17},
  abstract = {The uptake and consumption of Linked Data is currently restricted almost entirely to the Semantic Web community. While the utility of Linked Data to non-tech savvy web users is evident, the lack of technical knowledge and an understanding of the intricacies of the semantic technology stack limit such users in their ability to interpret and make use of the Web of Data. A key solution in overcoming this hurdle is to visualise Linked Data in a coherent and legible manner, allowing non-domain and non-technical audiences also to obtain a good understanding of its structure, and therefore implicitly compose queries, identify links between resources and intuitively discover new pieces of information. In this paper we describe key requirements which the visualisation of linked data must fulfil in order to lower the technical barrier and make the Web of Data accessible for all. We provide an extensive survey of current efforts in the Semantic Web community with respect to our requirements, and identify the potential for visual support to lead to more effective, intuitive interaction of the end user with Linked Data. We conclude with the conclusions drawn from our survey and analysis, and present proposals for advancing current Linked Data visualisation efforts.},
  file = {/home/alex/Zotero/storage/8YUKFJHB/Dadzie and Rowe - 2011 - Approaches to visualising Linked Data A survey.pdf},
  langid = {english},
  number = {2}
}

@online{DataGov,
  title = {Data.Gov},
  url = {https://www.data.gov/},
  urldate = {2021-04-12},
  abstract = {The home of the U.S. Government’s open data Here you will find data, tools, and resources to conduct research, develop web and mobile applications, design data visualizations, and more. For information regarding the Coronavirus/COVID-19, please visit Coronavirus.gov.},
  file = {/home/alex/Zotero/storage/6UH6VMFS/www.data.gov.html},
  langid = {american},
  organization = {{Data.gov}}
}

@online{DBnomics,
  title = {About {{DBnomics}}},
  url = {https://db.nomics.world/about},
  urldate = {2021-04-17},
  file = {/home/alex/Zotero/storage/SYMM3S35/about.html}
}

@article{dibiaData2VisAutomaticGeneration2019,
  title = {{{Data2Vis}}: {{Automatic Generation}} of {{Data Visualizations Using Sequence}}-to-{{Sequence Recurrent Neural Networks}}},
  shorttitle = {{{Data2Vis}}},
  author = {Dibia, Victor and Demiralp, Cagatay},
  date = {2019-09-01},
  journaltitle = {IEEE Computer Graphics and Applications},
  shortjournal = {IEEE Comput. Grap. Appl.},
  volume = {39},
  pages = {33--46},
  issn = {0272-1716, 1558-1756},
  doi = {10.1109/MCG.2019.2924636},
  url = {https://ieeexplore.ieee.org/document/8744242/},
  urldate = {2021-04-12},
  abstract = {Rapidly creating effective visualizations using expressive grammars is challenging for users who have limited time and limited skills in statistics and data visualization. Even high-level, dedicated visualization tools often require users to manually select among data attributes, decide which transformations to apply, and specify mappings between visual encoding variables and raw or transformed attributes. In this paper we introduce Data2Vis, an end-to-end trainable neural translation model for automatically generating visualizations from given datasets. We formulate visualization generation as a language translation problem where data specifications are mapped to visualization specifications in a declarative language (Vega-Lite). To this end, we train a multilayered attention-based encoder-decoder network with long short-term memory (LSTM) units on a corpus of visualization specifications. Qualitative results show that our model learns the vocabulary and syntax for a valid visualization specification, appropriate transformations (count, bins, mean) and how to use common data selection patterns that occur within data visualizations. Data2Vis generates visualizations that are comparable to manually-created visualizations in a fraction of the time, with potential to learn more complex visualization strategies at scale.},
  file = {/home/alex/Zotero/storage/4PB2XGPQ/Dibia and Demiralp - 2019 - Data2Vis Automatic Generation of Data Visualizati.pdf},
  langid = {english},
  number = {5}
}

@inproceedings{dimouRMLGenericLanguage2014,
  title = {{{RML}}: A Generic Language for Integrated {{RDF}} Mappings of Heterogeneous Data},
  shorttitle = {{{RML}}},
  booktitle = {Ldow},
  author = {Dimou, Anastasia and Vander Sande, Miel and Colpaert, Pieter and Verborgh, Ruben and Mannens, Erik and Van de Walle, Rik},
  date = {2014},
  file = {/home/alex/Zotero/storage/NRY9SK3S/Dimou et al. - 2014 - RML a generic language for integrated RDF mapping.pdf}
}

@article{dingTWCLOGDPortal2011,
  title = {{{TWC LOGD}}: {{A Portal}} for {{Linked Open Government Data Ecosystems}}},
  author = {Ding, Li and Lebo, Timothy and Erickson, John S. and DiFranzo, Dominic and Williams, Gregory Todd and Li, Xian and Michaelis, James and Graves, Alvaro and Zheng, Jin Guang and Shangguan, Zhenning and Flores, Johanna and McGuinness, Deborah L. and Hendler, Jim},
  date = {2011},
  journaltitle = {Web Semantics: Science, Services and Agents on the World Wide Web},
  volume = {In Press, Accepted Manuscript},
  issn = {1570-8268},
  doi = {DOI: 10.1016/j.websem.2011.06.002},
  url = {http://www.sciencedirect.com/science/article/pii/S1570826811000382}
}

@article{dingTWCLOGDPortal2011a,
  title = {{{TWC LOGD}}: {{A}} Portal for Linked Open Government Data Ecosystems},
  shorttitle = {{{TWC LOGD}}},
  author = {Ding, Li and Lebo, Timothy and Erickson, John S. and DiFranzo, Dominic and Williams, Gregory Todd and Li, Xian and Michaelis, James and Graves, Alvaro and Zheng, Jin Guang and Shangguan, Zhenning},
  date = {2011},
  journaltitle = {Journal of Web Semantics},
  volume = {9},
  pages = {325--333},
  publisher = {{Elsevier}},
  file = {/home/alex/Zotero/storage/5KBBRLEX/Ding et al. - 2011 - TWC LOGD A portal for linked open government data.pdf;/home/alex/Zotero/storage/VBDG3EB7/S1570826811000382.html},
  number = {3}
}

@article{ermilovCrowdSourcingLargeScaleSemantic,
  title = {Crowd-{{Sourcing}} the {{Large}}-{{Scale Semantic Mapping}} of {{Tabular Data}}},
  author = {Ermilov, Ivan and Auer, Soren and Stadler, Claus},
  pages = {10},
  abstract = {Governments and public administrations started recently to publish large amounts of structured data on the Web, mostly in the form of tabular data such as CSV files or Excel sheets. Various tools and projects have been launched aiming at facilitating the lifting of tabular data to reach semantically structured and linked data. However, none of these tools supported a truly incremental, pay-as-you-go data publication and mapping strategy, which enables effort sharing between data owners, community experts and consumers. In this article, we present an approach for enabling the crowd-sourcing of the large-scale semantic mapping of tabular data. We devise a simple mapping language for tabular data, which is easy to understand even for casual users, but expressive enough to cover the vast majority of potential tabular mappings use cases. Default mappings are automatically created and can be revised by the community using a semantic wiki. The mappings are executed using a sophisticated streaming RDB2RDF conversion. We report about the deployment of our approach at the Pan-European data portal PublicData.eu, where we transformed and enriched almost 10,000 datasets accounting for 7.3 billion triples.},
  file = {/home/alex/Zotero/storage/G5JSLKHL/Ermilov et al. - Crowd-Sourcing the Large-Scale Semantic Mapping of.pdf},
  langid = {english}
}

@inproceedings{ermilovCsv2rdfUserdrivenCsv2013,
  title = {Csv2rdf: {{User}}-Driven Csv to Rdf Mass Conversion Framework},
  shorttitle = {Csv2rdf},
  booktitle = {Proceedings of the {{ISEM}}},
  author = {Ermilov, Ivan and Auer, Sören and Stadler, Claus},
  date = {2013},
  volume = {13},
  pages = {04--06},
  file = {/home/alex/Zotero/storage/B7BBZNR4/Ermilov et al. - 2013 - Csv2rdf User-driven csv to rdf mass conversion fr.pdf}
}

@online{idehenSemanticWebLayer2017,
  title = {Semantic {{Web Layer Cake Tweak}}, {{Explained}}},
  author = {Idehen, Kingsley Uyi},
  date = {2017-07-24T14:27:28},
  url = {https://medium.com/openlink-software-blog/semantic-web-layer-cake-tweak-explained-6ba5c6ac3fab},
  urldate = {2021-04-17},
  abstract = {Tweak to the W3C’s Semantic Web Layer Cake illustration motivated by current usage},
  file = {/home/alex/Zotero/storage/N8AUQMR6/semantic-web-layer-cake-tweak-explained-6ba5c6ac3fab.html},
  langid = {english},
  organization = {{Medium}}
}

@online{IndexesDataQuality2015,
  title = {Indexes of {{Data Quality}} and {{Openness}}},
  date = {2015-12-19T17:37:56-05:00},
  url = {https://opendatawatch.com/blog/indexes-of-data-quality-and-openness/},
  urldate = {2021-04-12},
  abstract = {This article reviews three indexes that assess the openness~or~quality of data produced by national governments: The Open Data Barometer (ODB), the Open Data Index (ODI), and the World Bank’s Statistical Capacity Index (SCI).},
  file = {/home/alex/Zotero/storage/I46QKJCT/indexes-of-data-quality-and-openness.html},
  langid = {english},
  organization = {{Open Data Watch}}
}

@article{janevLOD2ToolValidating,
  title = {{{LOD2 Tool}} for {{Validating RDF Data Cube Models}}},
  author = {Janev, Valentina and Mijović, Vuk and Vraneš, Sanja},
  pages = {8},
  abstract = {The Open Government Data initiative aims at motivating governments and organizations to make information freely available and easily accessible online. This paper contributes to the understanding of the process of publishing public sector information as Linked Data, the use of the RDF Data Cube vocabulary and the LOD2 stack for publishing statistical data. In order to facilitate the publication process, a specialized component for the LOD2 Statistical workbench has been implemented – the RDF Data Cube Validation tool, (described in this paper). The tool can speed-up the processing and publishing Linked Data in RDF Data Cube format.},
  file = {/home/alex/Zotero/storage/P2KMF8XA/Janev et al. - LOD2 Tool for Validating RDF Data Cube Models.pdf},
  langid = {english}
}

@inproceedings{jimenez-ruizResultsSemTab20202020,
  title = {Results of {{SemTab}} 2020},
  booktitle = {{{SemTab}}@{{ISWC}}},
  author = {Jiménez-Ruiz, Ernesto and Hassanzadeh, Oktie and Efthymiou, Vasilis and Chen, Jiaoyan and Srinivas, Kavitha and Cutrona, Vincenzo},
  date = {2020},
  pages = {1--8},
  url = {http://ceur-ws.org/Vol-2775/paper0.pdf}
}

@online{klarmanLinkedOpenStatistical2020,
  title = {Linked {{Open Statistical Data}}, {{Served Simply}}},
  author = {Klarman, Szymon},
  date = {2020-02-04T08:36:54},
  url = {https://medium.com/@sklarman/linked-open-statistical-data-served-simply-ead245bf715},
  urldate = {2021-03-30},
  abstract = {Hiding the complexity of RDF Data Cubes behind GraphQL \& JSON-LD},
  file = {/home/alex/Zotero/storage/BML252FL/linked-open-statistical-data-served-simply-ead245bf715.html},
  langid = {english},
  organization = {{Medium}}
}

@article{klimekSurveyToolsLinked2019,
  title = {Survey of Tools for {{Linked Data}} Consumption},
  author = {Klímek, Jakub and Škoda, Petr and Nečaský, Martin},
  editor = {Verborgh, Ruben},
  date = {2019-05-23},
  journaltitle = {Semantic Web},
  shortjournal = {SW},
  volume = {10},
  pages = {665--720},
  issn = {22104968, 15700844},
  doi = {10.3233/SW-180316},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-180316},
  urldate = {2021-04-17},
  abstract = {There is lots of data published as Linked (Open) Data (LOD/LD). At the same time, there is also a multitude of tools for publication of LD. However, potential LD consumers still have difficulty discovering, accessing and exploiting LD. This is because compared to consumption of traditional data formats such as XML and CSV files, there is a distinct lack of tools for consumption of LD. The promoters of LD use the well-known 5-star Open Data deployment scheme to suggest that consumption of LD is a better experience once the consumer knows RDF and related technologies. This suggestion, however, falls short when the consumers search for an appropriate tooling support for LD consumption. In this paper we define a LD consumption process. Based on this process and current literature, we define a set of 36 requirements a hypothetical Linked Data Consumption Platform (LDCP) should ideally fulfill. We cover those requirements with a set of 93 evaluation criteria. We survey 110 tools identified as potential candidates for LDCP, eliminating them in 4 rounds until 9 candidates for LDCP remain. We evaluate the 9 candidates using our 93 criteria. Based on this evaluation we show which parts of the LD consumption process are covered by the 9 candidates. We also show that there are important LD consumption steps which are not sufficiently covered by existing tools. The authors of LDCP implementations may use our paper to decide about directions of future development of their tools. The paper can also be used as an introductory text to LD consumption.},
  file = {/home/alex/Zotero/storage/DV3MQCHU/Klímek et al. - 2019 - Survey of tools for Linked Data consumption.pdf},
  langid = {english},
  number = {4}
}

@article{knoblockInteractivelyMappingData,
  title = {Interactively {{Mapping Data Sources}} into the {{Semantic Web}}},
  author = {Knoblock, Craig A and Szekely, Pedro and Ambite, Jose Luis and Gupta, Shubham and Goel, Aman and Muslea, Maria and Lerman, Kristina and Mallick, Parag},
  pages = {12},
  abstract = {The Linked Open Data continues to grow rapidly, but a limitation of much of the data that is being published is the lack of a semantic description. While there are tools that help users to quickly convert a database into RDF, they do not provide a way to easily map the data into an existing ontology. This paper presents an approach that allows users to interactively map their structured sources into an existing ontology and then use that mapping to generate RDF triples. This approach automatically generates a mapping from the data source into the ontology, but since the precise mapping is sometimes ambiguous, we allow the user to interactively refine the mappings. We implemented this approach in a system called Karma, and demonstrate that the system can map sources into an ontology with minimal user interaction and efficiently generate the corresponding RDF.},
  file = {/home/alex/Zotero/storage/W7PRINJE/Knoblock et al. - Interactively Mapping Data Sources into the Semant.pdf},
  langid = {english}
}

@article{layered-grammar,
  title = {A Layered Grammar of Graphics},
  author = {Wickham, Hadley},
  date = {2010},
  journaltitle = {Journal of Computational and Graphical Statistics},
  volume = {19},
  pages = {3--28},
  doi = {10.1198/jcgs.2009.07098},
  url = {http://dx.doi.org/10.1198/jcgs.2009.07098},
  number = {1},
  selected = {TRUE}
}

@online{LinkedDataGlossary,
  title = {Linked {{Data Glossary}}},
  url = {https://dvcs.w3.org/hg/gld/raw-file/default/glossary/index.html#x5-star-linked-open-data},
  urldate = {2021-04-12},
  file = {/home/alex/Zotero/storage/X783N8DK/index.html}
}

@online{LinkedStatisticalData,
  title = {Linked {{Statistical Data Analysis}}},
  url = {https://csarven.ca/linked-statistical-data-analysis},
  urldate = {2021-04-17},
  file = {/home/alex/Zotero/storage/YR7QHWCE/linked-statistical-data-analysis.html}
}

@inproceedings{martinCubevizExplorationVisualization2015,
  title = {Cubeviz: {{Exploration}} and Visualization of Statistical Linked Data},
  shorttitle = {Cubeviz},
  booktitle = {Proceedings of the 24th {{International Conference}} on {{World Wide Web}}},
  author = {Martin, Michael and Abicht, Konrad and Stadler, Claus and Ngonga Ngomo, Axel-Cyrille and Soru, Tommaso and Auer, Sören},
  date = {2015},
  pages = {219--222},
  file = {/home/alex/Zotero/storage/R3E73X4J/Martin et al. - 2015 - Cubeviz Exploration and visualization of statisti.pdf;/home/alex/Zotero/storage/M5ZD7SUH/2740908.html}
}

@article{mulwadAutomaticallyGeneratingGovernment,
  title = {Automatically {{Generating Government Linked Data}} from {{Tables}}},
  author = {Mulwad, Varish and Finin, Tim and Joshi, Anupam},
  pages = {7},
  abstract = {Most open government data is encoded and published in structured tables found in reports, on the Web, and in spreadsheets or databases. Current approaches to generating Semantic Web representations from such data requires human input to create schemas and often results in graphs that do not follow best practices for linked data. Evidence for a table’s meaning can be found in its column headers, cell values, implicit relations between columns, caption and surrounding text but also requires general and domain-specific background knowledge. We describe techniques grounded in graphical models and probabilistic reasoning to infer meaning (semantics) associated with a table using background knowledge from the Linked Open Data cloud. We represent a table’s meaning by mapping columns to classes in an appropriate ontology, linking cell values to literal constants, implied measurements, or entities in the linked data cloud (existing or new) and discovering or and identifying relations between columns.},
  file = {/home/alex/Zotero/storage/EQ3GEKIS/Mulwad et al. - Automatically Generating Government Linked Data fr.pdf},
  langid = {english}
}

@article{nentwigSurveyCurrentLink2016,
  title = {A Survey of Current {{Link Discovery}} Frameworks},
  author = {Nentwig, Markus and Hartung, Michael and Ngonga Ngomo, Axel-Cyrille and Rahm, Erhard},
  editor = {Noy, Natasha},
  date = {2016-12-06},
  journaltitle = {Semantic Web},
  shortjournal = {SW},
  volume = {8},
  pages = {419--436},
  issn = {22104968, 15700844},
  doi = {10.3233/SW-150210},
  url = {https://www.medra.org/servlet/aliasResolver?alias=iospress&doi=10.3233/SW-150210},
  urldate = {2021-04-12},
  abstract = {Links build the backbone of the Linked Data Cloud. With the steady growth in size of datasets comes an increased need for end users to know which frameworks to use for deriving links between datasets. In this survey, we comparatively evaluate current Link Discovery tools and frameworks. For this purpose, we outline general requirements and derive a generic architecture of Link Discovery frameworks. Based on this generic architecture, we study and compare the features of state-ofthe-art linking frameworks. We also analyze reported performance evaluations for the different frameworks. Finally, we derive insights pertaining to possible future developments in the domain of Link Discovery.},
  file = {/home/alex/Zotero/storage/UZM4X7PQ/Nentwig et al. - 2016 - A survey of current Link Discovery frameworks.pdf},
  langid = {english},
  number = {3}
}

@article{ngongangomoLIMESFrameworkLink2021,
  title = {{{LIMES}}: {{A Framework}} for {{Link Discovery}} on the {{Semantic Web}}},
  shorttitle = {{{LIMES}}},
  author = {Ngonga Ngomo, Axel-Cyrille and Sherif, Mohamed Ahmed and Georgala, Kleanthi and Hassan, Mofeed Mohamed and Dreßler, Kevin and Lyko, Klaus and Obraczka, Daniel and Soru, Tommaso},
  date = {2021-03-17},
  journaltitle = {KI - Künstliche Intelligenz},
  shortjournal = {Künstl Intell},
  issn = {0933-1875, 1610-1987},
  doi = {10.1007/s13218-021-00713-x},
  url = {http://link.springer.com/10.1007/s13218-021-00713-x},
  urldate = {2021-04-12},
  abstract = {The Linked Data paradigm builds upon the backbone of distributed knowledge bases connected by typed links. The mere volume of current knowledge bases as well as their sheer number pose two major challenges when aiming to support the computation of links across and within them. The first is that tools for link discovery have to be time-efficient when they compute links. Secondly, these tools have to produce links of high quality to serve the applications built upon Linked Data well. The current version of the LIMES framework is the product of seven years of research on these two challenges. The framework combines diverse algorithms for link discovery within a generic and extensible architecture. In this system paper, we give an overview of the 1.0 open-source release of the framework. In particular, we focus on an overview of the architecture of the framework, an intuition of its inner workings and a brief overview of the approaches it contains. Some of the applications within which the framework was used complete the paper. Our framework is open-source and available under a dual license at http://github.com/aksw/limes-dev together with a user manual and a developer manual.},
  file = {/home/alex/Zotero/storage/94TV3GQ9/Ngonga Ngomo et al. - 2021 - LIMES A Framework for Link Discovery on the Seman.pdf},
  langid = {english}
}

@online{RDFDataCube,
  title = {The {{RDF Data Cube Vocabulary}}},
  url = {https://www.w3.org/TR/vocab-data-cube/},
  urldate = {2021-04-17},
  file = {/home/alex/Zotero/storage/VCHGEJHF/vocab-data-cube.html}
}

@article{satyanarayanReactiveVegaStreaming2015,
  title = {Reactive Vega: {{A}} Streaming Dataflow Architecture for Declarative Interactive Visualization},
  shorttitle = {Reactive Vega},
  author = {Satyanarayan, Arvind and Russell, Ryan and Hoffswell, Jane and Heer, Jeffrey},
  date = {2015},
  journaltitle = {IEEE transactions on visualization and computer graphics},
  volume = {22},
  pages = {659--668},
  publisher = {{IEEE}},
  file = {/home/alex/Zotero/storage/TFYZTKPA/7192704.html},
  number = {1}
}

@article{satyanarayanVegaliteGrammarInteractive2016,
  title = {Vega-Lite: {{A}} Grammar of Interactive Graphics},
  shorttitle = {Vega-Lite},
  author = {Satyanarayan, Arvind and Moritz, Dominik and Wongsuphasawat, Kanit and Heer, Jeffrey},
  date = {2016},
  journaltitle = {IEEE transactions on visualization and computer graphics},
  volume = {23},
  pages = {341--350},
  publisher = {{IEEE}},
  file = {/home/alex/Zotero/storage/FDK5NCUE/7539624.html},
  number = {1}
}

@online{StatisticalLinkedDataspaces,
  title = {Statistical {{Linked Dataspaces}}},
  url = {https://csarven.ca/statistical-linked-dataspaces##related-work},
  urldate = {2021-04-17},
  file = {/home/alex/Zotero/storage/CDYV2K4G/statistical-linked-dataspaces.html}
}

@online{SustainabilityPlan,
  title = {Sustainability {{Plan}}},
  url = {https://github.com/comunica/comunica/wiki/Sustainability-Plan},
  urldate = {2021-04-17},
  abstract = {📬 A knowledge graph querying framework for JavaScript - comunica/comunica},
  file = {/home/alex/Zotero/storage/DCPUB5C3/Sustainability-Plan.html},
  langid = {english},
  organization = {{GitHub}}
}

@online{TWCLOGDPortal,
  title = {{{TWC LOGD}}: {{A}} Portal for Linked Open Government Data Ecosystems - {{ScienceDirect}}},
  url = {https://www.sciencedirect.com/science/article/abs/pii/S1570826811000382},
  urldate = {2021-04-12},
  file = {/home/alex/Zotero/storage/EUAINL3I/S1570826811000382.html}
}

@online{UKGovLDPublishingstatisticaldata,
  title = {{{UKGovLD}}/Publishing-Statistical-Data},
  url = {https://github.com/UKGovLD/publishing-statistical-data},
  urldate = {2021-04-17},
  abstract = {Automatically exported from code.google.com/p/publishing-statistical-data - UKGovLD/publishing-statistical-data},
  file = {/home/alex/Zotero/storage/3ML89ZSQ/vocab.html},
  langid = {english},
  organization = {{GitHub}}
}

@incollection{vanderwaalLiftingOpenData2014,
  title = {Lifting Open Data Portals to the Data Web},
  booktitle = {Linked {{Open Data}}–{{Creating Knowledge Out}} of {{Interlinked Data}}},
  author = {van der Waal, Sander and Węcel, Krzysztof and Ermilov, Ivan and Janev, Valentina and Milošević, Uroš and Wainwright, Mark},
  date = {2014},
  pages = {175--195},
  publisher = {{Springer}},
  file = {/home/alex/Zotero/storage/E983L8UW/978-3-319-09846-3_9.html},
  options = {useprefix=true}
}

@online{W3CSemanticWeb,
  title = {{{W3C Semantic Web Activity}}},
  url = {https://www.w3.org/2001/12/semweb-fin/w3csw},
  urldate = {2021-04-17},
  file = {/home/alex/Zotero/storage/JI36XITQ/w3csw.html}
}

@article{wickhamTidyData2014,
  title = {Tidy {{Data}}},
  author = {Wickham, Hadley},
  date = {2014},
  journaltitle = {Journal of Statistical Software},
  shortjournal = {J. Stat. Soft.},
  volume = {59},
  issn = {1548-7660},
  doi = {10.18637/jss.v059.i10},
  url = {http://www.jstatsoft.org/v59/i10/},
  urldate = {2021-04-17},
  file = {/home/alex/Zotero/storage/HAPEQEPA/Wickham - 2014 - Tidy Data.pdf},
  langid = {english},
  number = {10}
}


